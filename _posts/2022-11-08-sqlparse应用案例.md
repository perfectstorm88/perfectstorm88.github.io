# 介绍
sqlparse是一个无验证的SQL解析器。它提供了解析、拆分、格式化SQL语句的能力。

sqlparse提供了三个基本的函数，用于SQL语句处理。

- split:拆分包含多个SQL语句的字符串为SQL语句列表,语句结尾通过;分隔。

- format:将SQL语句格式化，以便更清晰的展现。

- parse:parse()返回sql解析结果tuple,tuple的每个元素对应于split()的一个SQL语句,解析的结果也可以通过str()生成原始的SQL语句。

其代码主要结构为：

- 词法解析(tokenize)：关键词匹配规则：keywords.py和词法解析器：lexer.py
- 语句拆分(sqlparse.split)：语句切分程序：filter_stack.py -> statement_splitter.py
- 语法解析(sqlparse.parse)：filter_stack.py -> statement_splitter.py grouping.py
    - group代码：grouping.py。定义了各种SQL语法的解析规则，每种规则一般分为两部：
        - 识别语法相关语句，依赖token_next_by；
        - 调整语法树结构，依赖group_tokens。（group之后的结果，形成了语法树层次）
- SQL格式化(sqlparse.format)

# 应用案例
下面是一个应用场景：

## 从查询SQL中抽取返回字段名



```python
import sqlparse
from sqlparse.sql import IdentifierList, Identifier
from sqlparse.tokens import Keyword, DML
s = '''

---test 

select padua_t1.patient_case_id  ,  padua_t1.danger_level as padua,padua_t1.danger_level as padua2 from b_task padua_t1 join( 
select max(padua_t.id) id  
from b_task padua_t where padua_t.patient_case_id in(
        select patient_case_id from b_statistic_detail  where discharge_time is null  -- 在院病人
    )  and padua_t.ass_type =2 group by padua_t.patient_case_id ) padua_t0
on padua_t1.id = padua_t0.id;


select patient_case_id,max(danger_level) as opt_post_pe_c
from b_task opt_post_pe_c_t where opt_post_pe_c_t.patient_case_id in(
        select patient_case_id from b_statistic_detail  where discharge_time is null  -- 在院病人
    )  and opt_post_pe_c_t.tri_ass_type=3 and opt_post_pe_c_t.ass_type IN(16) and opt_post_pe_c_t.status and opt_post_pe_c_t.status = 2 group by opt_post_pe_c_t.patient_case_id 
'''
r = sqlparse.parse(s)[0]

# print(r.tokens)
def extrat_columns(r):
    identifier_pre_from = None
    select_columns = []
    # 取第一层的select .. from 之间的标识符
    is_start_select = False
    for item in r.tokens:  # 第二个就是
        if item.ttype is DML and item.value.upper() == 'SELECT':
            is_start_select = True
        elif item.ttype is Keyword and item.value.upper() == 'FROM':
            break  # 结束搜索
        elif isinstance(item, Identifier):
            print('Identifier',item)
            select_columns.append(item.get_name())
        elif isinstance(item, IdentifierList):
            print('IdentifierList',item)
            for item2 in item.get_identifiers():
                select_columns.append(item2.get_name())
    print('结果集的字段列表', select_columns)    
                
    
extrat_columns(sqlparse.parse(s)[0])    
extrat_columns(sqlparse.parse(s)[1])    
```

## 案例：从查询SQL中抽取表名

```python
import sqlparse
from sqlparse.sql import IdentifierList, Identifier
from sqlparse.tokens import Keyword, DML


def is_subselect(parsed):
    if not parsed.is_group:
        return False
    for item in parsed.tokens:
        if item.ttype is DML and item.value.upper() == 'SELECT':
            return True
    return False


def extract_from_part(parsed):
    from_seen = False
    for item in parsed.tokens:
        if from_seen:
            if is_subselect(item):
                yield from extract_from_part(item)
            elif item.ttype is Keyword:
                return
            else:
                yield item
        elif item.ttype is Keyword and item.value.upper() == 'FROM':
            from_seen = True


def extract_table_identifiers(token_stream):
    for item in token_stream:
        if isinstance(item, IdentifierList):
            for identifier in item.get_identifiers():
                yield identifier.get_name()
        elif isinstance(item, Identifier):
            yield item.get_name()
        # It's a bug to check for Keyword here, but in the example
        # above some tables names are identified as keywords...
        elif item.ttype is Keyword:
            yield item.value


def extract_tables(sql):
    stream = extract_from_part(sqlparse.parse(sql)[0])
    return list(extract_table_identifiers(stream))

extract_tables(s)
```
## 案例：从创建SQL中抽取字段名
```python

import sqlparse
def extract_definitions(token_list):
    # assumes that token_list is a parenthesis
    definitions = []
    tmp = []
    par_level = 0
    for token in token_list.flatten():
        if token.is_whitespace:
            continue
        elif token.match(sqlparse.tokens.Punctuation, '('):
            par_level += 1
            continue
        if token.match(sqlparse.tokens.Punctuation, ')'):
            if par_level == 0:
                break
            else:
                par_level += 1
        elif token.match(sqlparse.tokens.Punctuation, ','):
            if tmp:
                definitions.append(tmp)
            tmp = []
        else:
            tmp.append(token)
    if tmp:
        definitions.append(tmp)
    return definitions


SQL = """CREATE TABLE foo (
         id integer primary key,
         title varchar(200) not null,
         description text);"""

parsed = sqlparse.parse(SQL)[0]

# extract the parenthesis which holds column definitions
_, par = parsed.token_next_by(i=sqlparse.sql.Parenthesis)
columns = extract_definitions(par)

for column in columns:
    print('NAME: {name!s:12} DEFINITION: {definition}'.format(
        name=column[0], definition=' '.join(str(t) for t in column[1:])))
```


## 参考
- [SQL解析系列(Python)--sqlparse源码](https://zhuanlan.zhihu.com/p/279297051) 
- [sqlparse中的两个案例](https://github.com/andialbrecht/sqlparse/tree/master/examples)
